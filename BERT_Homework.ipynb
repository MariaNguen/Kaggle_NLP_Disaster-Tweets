{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPUs0X8x+FY0QGukeQZrwrt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MariaNguen/Kaggle_NLP_Disaster-Tweets/blob/main/BERT_Homework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Домашнее задание \"Почувствуй мощь трансформеров в бою\""
      ],
      "metadata": {
        "id": "wheiLzcKDqsb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В качестве данных выберете возьмите датасет RuCola для русского языка https://github.com/RussianNLP/RuCoLA (в качестве train возьмите in_domain_train.csv, а в качестве теста in_domain_dev.csv)\n",
        "\n",
        "Разбейте in_domain_train на train и val\n",
        "\n",
        "Зафайнтьюньте и протестируйте RuBert или RuRoBerta на данной задаче (можно взять любую предобученную модель руберт с сайта huggingface. Например, ruBert-base/large https://huggingface.co/sberbank-ai/ruBert-base / https://huggingface.co/sberbank-ai/ruBert-large или rubert-base-cased https://huggingface.co/DeepPavlov/rubert-base-cased, ruRoberta-large https://huggingface.co/sberbank-ai/ruRoberta-large, xlm-roberta-base https://huggingface.co/xlm-roberta-base)\n",
        "\n",
        "Возьмите RuGPT3 base или large и решите данное задание с помощью методов few-/zero-shot\n",
        "\n",
        "а) переберите несколько вариантов затравок\n",
        "\n",
        "б) протестируйте различное число few-shot примеров (0, 1, 2, 4)\n",
        "\n",
        "Обучите и протестируйте модель RuT5 на данной задаче (пример finetun’а можете найти здесь https://github.com/RussianNLP/RuCoLA/blob/main/baselines/finetune_t5.py)\n",
        "Сравните полученные результаты"
      ],
      "metadata": {
        "id": "g7i0qjT1O7eg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sOwZDaAn1NZk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d9061a2-08d8-4d73-e1f8-409510d600f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "8NVIOjy61aYX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb84d91c-51d1-4761-879c-f40804d1d91f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Загрузка данных"
      ],
      "metadata": {
        "id": "VLHrd1G9Wfvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"/content/in_domain_train.csv\", sep=',', on_bad_lines='skip')\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "u1MKJTXGSy9V",
        "outputId": "4ddfe292-912c-49c5-be86-6e2f3cee134d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sentences: 7,869\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id                                           sentence  acceptable  \\\n",
              "5024  5024                        Мне слышится что-то родное.           1   \n",
              "7570  7570  Увидев Андрея рядом с командиром, всё стало ле...           0   \n",
              "6485  6485  И вдруг однажды замечаю, что в одной из бутыло...           1   \n",
              "4066  4066  Соломон Волков хочет насильно выпустить книгу ...           1   \n",
              "6621  6621  После этого я получила отвращение к азартным и...           1   \n",
              "5779  5779  Осип Брик в ряде статей обнаружил, что он нико...           1   \n",
              "133    133                     Иван знает, что приехала Маша.           1   \n",
              "408    408                 Фишер уронил себя отказом от игры.           1   \n",
              "2022  2022                         Мальчик высунулся из окна.           1   \n",
              "2918  2918      С такими, как он, часто что-нибудь случается.           1   \n",
              "\n",
              "     error_type detailed_source  \n",
              "5024          0   Paducheva2004  \n",
              "7570     Syntax            USE8  \n",
              "6485          0         Rusgram  \n",
              "4066          0       Testelets  \n",
              "6621          0    Seliverstova  \n",
              "5779          0   Paducheva2004  \n",
              "133           0   Paducheva2013  \n",
              "408           0   Paducheva2013  \n",
              "2022          0   Paducheva2010  \n",
              "2918          0         Rusgram  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-bae2ecdd-4fa5-4656-90c6-b02dc42e7277\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>acceptable</th>\n",
              "      <th>error_type</th>\n",
              "      <th>detailed_source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5024</th>\n",
              "      <td>5024</td>\n",
              "      <td>Мне слышится что-то родное.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Paducheva2004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7570</th>\n",
              "      <td>7570</td>\n",
              "      <td>Увидев Андрея рядом с командиром, всё стало ле...</td>\n",
              "      <td>0</td>\n",
              "      <td>Syntax</td>\n",
              "      <td>USE8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6485</th>\n",
              "      <td>6485</td>\n",
              "      <td>И вдруг однажды замечаю, что в одной из бутыло...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Rusgram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4066</th>\n",
              "      <td>4066</td>\n",
              "      <td>Соломон Волков хочет насильно выпустить книгу ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Testelets</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6621</th>\n",
              "      <td>6621</td>\n",
              "      <td>После этого я получила отвращение к азартным и...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Seliverstova</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5779</th>\n",
              "      <td>5779</td>\n",
              "      <td>Осип Брик в ряде статей обнаружил, что он нико...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Paducheva2004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>133</td>\n",
              "      <td>Иван знает, что приехала Маша.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Paducheva2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>408</th>\n",
              "      <td>408</td>\n",
              "      <td>Фишер уронил себя отказом от игры.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Paducheva2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022</th>\n",
              "      <td>2022</td>\n",
              "      <td>Мальчик высунулся из окна.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Paducheva2010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2918</th>\n",
              "      <td>2918</td>\n",
              "      <td>С такими, как он, часто что-нибудь случается.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Rusgram</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bae2ecdd-4fa5-4656-90c6-b02dc42e7277')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-808b964c-88ed-4d21-8650-4e53bb9a835d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-808b964c-88ed-4d21-8650-4e53bb9a835d')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-808b964c-88ed-4d21-8650-4e53bb9a835d button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bae2ecdd-4fa5-4656-90c6-b02dc42e7277 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bae2ecdd-4fa5-4656-90c6-b02dc42e7277');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset into a pandas dataframe.\n",
        "test = pd.read_csv(\"/content/in_domain_dev.csv\", sep=',', on_bad_lines='skip')\n",
        "\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(test.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "test.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "lVHonyNUTapD",
        "outputId": "22ac8a81-62c6-4afa-fa69-0fe8c3b9bb8e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test sentences: 983\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id                                           sentence  acceptable  \\\n",
              "562  562                            Человек смотрит в окно.           1   \n",
              "147  147  Между тем он по-прежнему отрицает свою вину, г...           1   \n",
              "99    99                       Этот будь был очень тяжелым.           0   \n",
              "471  471  Поход на пляж не должен окончиться неприятност...           1   \n",
              "102  102              Меня рассердила его невнимательность.           1   \n",
              "458  458                  Близ стола стояло большое кресло.           0   \n",
              "838  838          Она не будет менять свой план из-за тебя.           1   \n",
              "543  543     Букинист с особой целью продал книгу студенту.           1   \n",
              "883  883      Вообще-то он в институте, но сейчас он вышел.           1   \n",
              "17    17                          Кожа у виска была желтой.           1   \n",
              "\n",
              "    error_type detailed_source  \n",
              "562          0   Paducheva2004  \n",
              "147          0   Paducheva2004  \n",
              "99      Syntax       Testelets  \n",
              "471          0   Paducheva2013  \n",
              "102          0   Paducheva2004  \n",
              "458  Semantics    Seliverstova  \n",
              "838          0   Paducheva2013  \n",
              "543          0       Testelets  \n",
              "883          0    Seliverstova  \n",
              "17           0    Seliverstova  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-929efea1-bfee-429a-8002-6cb33e0fa2d7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>acceptable</th>\n",
              "      <th>error_type</th>\n",
              "      <th>detailed_source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>562</th>\n",
              "      <td>562</td>\n",
              "      <td>Человек смотрит в окно.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Paducheva2004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>147</td>\n",
              "      <td>Между тем он по-прежнему отрицает свою вину, г...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Paducheva2004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>Этот будь был очень тяжелым.</td>\n",
              "      <td>0</td>\n",
              "      <td>Syntax</td>\n",
              "      <td>Testelets</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>471</th>\n",
              "      <td>471</td>\n",
              "      <td>Поход на пляж не должен окончиться неприятност...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Paducheva2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>102</td>\n",
              "      <td>Меня рассердила его невнимательность.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Paducheva2004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458</th>\n",
              "      <td>458</td>\n",
              "      <td>Близ стола стояло большое кресло.</td>\n",
              "      <td>0</td>\n",
              "      <td>Semantics</td>\n",
              "      <td>Seliverstova</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>838</th>\n",
              "      <td>838</td>\n",
              "      <td>Она не будет менять свой план из-за тебя.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Paducheva2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>543</th>\n",
              "      <td>543</td>\n",
              "      <td>Букинист с особой целью продал книгу студенту.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Testelets</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>883</th>\n",
              "      <td>883</td>\n",
              "      <td>Вообще-то он в институте, но сейчас он вышел.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Seliverstova</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>Кожа у виска была желтой.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Seliverstova</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-929efea1-bfee-429a-8002-6cb33e0fa2d7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-c3f56ee6-9529-4cf3-acca-9d7a7f6dce2d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c3f56ee6-9529-4cf3-acca-9d7a7f6dce2d')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-c3f56ee6-9529-4cf3-acca-9d7a7f6dce2d button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-929efea1-bfee-429a-8002-6cb33e0fa2d7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-929efea1-bfee-429a-8002-6cb33e0fa2d7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RuBERT"
      ],
      "metadata": {
        "id": "i7c7UAtnEqFs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Токенизация"
      ],
      "metadata": {
        "id": "5-fhB_7iYoha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('ai-forever/ruBert-base')\n",
        "tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68MLi-F3YOR6",
        "outputId": "d9a8329c-0073-4cb1-c461-fb96f805e73b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertTokenizer(name_or_path='ai-forever/ruBert-base', vocab_size=120138, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', df['sentence'][0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(df['sentence'][0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(df['sentence'][0])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQIR1UXFZ8Jg",
        "outputId": "d6bf7dc1-61c7-4eb4-bf62-f220f735b368"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  Вдруг решетка беззвучно поехала в сторону, и на балконе возникла таинственная фигура, прячущаяся от лунного света, и погрозила Ивану пальцем.\n",
            "Tokenized:  ['вдруг', 'решетка', 'беззвучно', 'поехала', 'в', 'сторону', ',', 'и', 'на', 'балконе', 'возникла', 'таинственная', 'фигура', ',', 'прячу', '##щаяся', 'от', 'лунного', 'света', ',', 'и', 'погрозил', '##а', 'ива', '##ну', 'пальцем', '.']\n",
            "Token IDs:  [3014, 83321, 41548, 32350, 113, 2931, 121, 107, 660, 50354, 13779, 99183, 15226, 121, 94376, 19913, 700, 55918, 6412, 121, 107, 95640, 377, 104691, 717, 11420, 126]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in df['sentence']:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Max sentence length: ', max_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hxs_l_QBaBk-",
        "outputId": "cf1d01a0-ac83-4c9b-f5c8-9f305246f1b3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length:  45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in df['sentence']:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 50,           # Pad & truncate all sentences.\n",
        "                        truncation = True,\n",
        "                        padding='max_length',\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "\n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(df['acceptable'])\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', df['sentence'][0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcJHtvl9bXpj",
        "outputId": "3c6a373d-81c9-4006-ff97-55b461edd3b4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  Вдруг решетка беззвучно поехала в сторону, и на балконе возникла таинственная фигура, прячущаяся от лунного света, и погрозила Ивану пальцем.\n",
            "Token IDs: tensor([   101,   3014,  83321,  41548,  32350,    113,   2931,    121,    107,\n",
            "           660,  50354,  13779,  99183,  15226,    121,  94376,  19913,    700,\n",
            "         55918,   6412,    121,    107,  95640,    377, 104691,    717,  11420,\n",
            "           126,    102,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training and validation split"
      ],
      "metadata": {
        "id": "yGKNpKEVcyz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrciWBgwbZAs",
        "outputId": "5445a202-0ba4-40be-bb19-fe621c4f8f40"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7,082 training samples\n",
            "  787 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим также итератор."
      ],
      "metadata": {
        "id": "ZUN1bFavdA-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it\n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch\n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order.\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "dSRPydUCbZQ7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Обучение модели"
      ],
      "metadata": {
        "id": "JxAhyLOgdeT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single\n",
        "# linear classification layer on top.\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"ai-forever/ruBert-base\", # Use ruBert-base\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeBlGLOobZi9",
        "outputId": "ad01a913-96e8-427e-8b30-233396a643a8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ai-forever/ruBert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(120138, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(),\n",
        "                  lr = 1e-5,\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "metadata": {
        "id": "fu1ThNjMbX6f"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4.\n",
        "# We chose to run for 3, because the model overfits on 4 epochs\n",
        "epochs = 3\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs].\n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "2oW5nPh6WUo-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вспомогательная функция для вычисления точности."
      ],
      "metadata": {
        "id": "rAwFzoY0en7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "AVJIg3XkYCES"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вспомогательная функция для отслеживания затраченного времени."
      ],
      "metadata": {
        "id": "XRZzekGnewHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "metadata": {
        "id": "XxJGT5_faet9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запускаем обучение."
      ],
      "metadata": {
        "id": "jwYc_XSee94c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss,\n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to\n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader.\n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the\n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because\n",
        "        # accumulating the gradients is \"convenient while training RNNs\".\n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here:\n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        res = model(b_input_ids,\n",
        "                             token_type_ids=None,\n",
        "                             attention_mask=b_input_mask,\n",
        "                             labels=b_labels)\n",
        "        loss = res['loss']\n",
        "        logits = res['logits']\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value\n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        # Unpack this training batch from our dataloader.\n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using\n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which\n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here:\n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            res = model(b_input_ids,\n",
        "                                   token_type_ids=None,\n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "        loss = res['loss']\n",
        "        logits = res['logits']\n",
        "\n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWoNjP6Ge1Lk",
        "outputId": "be300047-a362-421c-ce27-69afbf75b885"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    222.    Elapsed: 0:00:12.\n",
            "  Batch    80  of    222.    Elapsed: 0:00:25.\n",
            "  Batch   120  of    222.    Elapsed: 0:00:36.\n",
            "  Batch   160  of    222.    Elapsed: 0:00:48.\n",
            "  Batch   200  of    222.    Elapsed: 0:00:59.\n",
            "\n",
            "  Average training loss: 0.55\n",
            "  Training epcoh took: 0:01:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.77\n",
            "  Validation Loss: 0.52\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    222.    Elapsed: 0:00:12.\n",
            "  Batch    80  of    222.    Elapsed: 0:00:23.\n",
            "  Batch   120  of    222.    Elapsed: 0:00:35.\n",
            "  Batch   160  of    222.    Elapsed: 0:00:47.\n",
            "  Batch   200  of    222.    Elapsed: 0:00:59.\n",
            "\n",
            "  Average training loss: 0.45\n",
            "  Training epcoh took: 0:01:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.50\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch    40  of    222.    Elapsed: 0:00:12.\n",
            "  Batch    80  of    222.    Elapsed: 0:00:23.\n",
            "  Batch   120  of    222.    Elapsed: 0:00:35.\n",
            "  Batch   160  of    222.    Elapsed: 0:00:46.\n",
            "  Batch   200  of    222.    Elapsed: 0:00:58.\n",
            "\n",
            "  Average training loss: 0.37\n",
            "  Training epcoh took: 0:01:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "  Validation Loss: 0.49\n",
            "  Validation took: 0:00:02\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:03:21 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим на саммари обучающего процесса."
      ],
      "metadata": {
        "id": "p7zwvNDCfLFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "#pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "WTXcAxMFfClR",
        "outputId": "b468deaa-997f-4fe9-b3b8-569fc8ef64b8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1           0.549253     0.515040       0.765329       0:01:05         0:00:02\n",
              "2           0.452035     0.499187       0.784079       0:01:05         0:00:02\n",
              "3           0.366303     0.488552       0.804474       0:01:04         0:00:02"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-12f15ff4-c0dc-4c6a-9bce-4137da51b122\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.549253</td>\n",
              "      <td>0.515040</td>\n",
              "      <td>0.765329</td>\n",
              "      <td>0:01:05</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.452035</td>\n",
              "      <td>0.499187</td>\n",
              "      <td>0.784079</td>\n",
              "      <td>0:01:05</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.366303</td>\n",
              "      <td>0.488552</td>\n",
              "      <td>0.804474</td>\n",
              "      <td>0:01:04</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12f15ff4-c0dc-4c6a-9bce-4137da51b122')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-2ff6f45a-c90f-4a13-982f-d2bf6d109d21\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2ff6f45a-c90f-4a13-982f-d2bf6d109d21')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-2ff6f45a-c90f-4a13-982f-d2bf6d109d21 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-12f15ff4-c0dc-4c6a-9bce-4137da51b122 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-12f15ff4-c0dc-4c6a-9bce-4137da51b122');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "w4ar9wpdfQFi",
        "outputId": "103b3d56-ae86-404c-8222-32efb474462d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Тестирование модели"
      ],
      "metadata": {
        "id": "NsKqjzw7fehY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Предобработаем тестовый датасет так, как мы предобрабатывали обучающий и валидационный."
      ],
      "metadata": {
        "id": "YJr8Wpk4frNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = test.sentence.values\n",
        "labels = test.acceptable.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 50,           # Pad & truncate all sentences.\n",
        "                        padding='max_length',\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "\n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "G7ZDDrwdfkTr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict\n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  # Telling the model not to compute or store gradients, saving memory and\n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids, token_type_ids=None,\n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GU6dHyR_ggIm",
        "outputId": "4c125010-90c9-4fe4-c170-09f9a0e05cd3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 983 test sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Positive samples: %d of %d (%.2f%%)' % (test.acceptable.sum(), len(test.acceptable), (test.acceptable.sum() / len(test.acceptable) * 100.0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUXUK-7LgkoB",
        "outputId": "867ff60c-57fa-4338-8707-7d82315a0eb9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive samples: 733 of 983 (74.57%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "\n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\"\n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "\n",
        "  # Calculate and store the coef for this batch.\n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)\n",
        "  matthews_set.append(matthews)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyyQtK6hgquW",
        "outputId": "460d08d0-bb38-4956-8040-5b30fb53188c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "# Combine the results across all batches.\n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THKf0605iXuv",
        "outputId": "1343f693-d24a-4a0b-cf18-dd28e405b2c2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MCC: 0.332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RuGPT-3"
      ],
      "metadata": {
        "id": "37-OgfZdGlho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/rugpt3large_based_on_gpt2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"ai-forever/rugpt3large_based_on_gpt2\")\n",
        "\n",
        "model.cuda()"
      ],
      "metadata": {
        "id": "PBjQBQlDihV_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24e951b1-36e8-4ae9-a6e7-a4ac615c117f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 1536)\n",
              "    (wpe): Embedding(2048, 1536)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-23): 24 x GPT2Block(\n",
              "        (ln_1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1536, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss function"
      ],
      "metadata": {
        "id": "ILXjv3HJLA2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def calc_loss(phrase: str,\n",
        "                        tokenizer,\n",
        "                        model):\n",
        "\n",
        "    phrase = tokenizer.encode(phrase)\n",
        "    # Если длина фразы 1 токен, то дальше ошибка вылезет :(\n",
        "    if len(phrase) == 1:\n",
        "         phrase.append(tokenizer.eos_token_id)\n",
        "    phrase = torch.tensor(phrase, dtype=torch.long, device=device)\n",
        "    phrase = phrase.unsqueeze(0)  # .repeat(num_samples, 1)\n",
        "    with torch.no_grad():\n",
        "        loss = model(phrase, labels=phrase)\n",
        "\n",
        "    loss[0].item()\n",
        "\n",
        "\n",
        "    return loss[0].item()\n",
        "\n",
        "def get_loss_num(text):\n",
        "    loss = calc_loss(phrase=text, model=model, tokenizer=tokenizer)\n",
        "    return loss\n",
        "\n",
        "def clean(text):\n",
        "    text = re.sub(r'\\((\\d+)\\)', '', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "jWCMGvZ9H4Z0"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zero-shot"
      ],
      "metadata": {
        "id": "lK1okOOELKkp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Напишем функцию, котора будет предсказывать корректность предложения. На вход будет получать затравки для корректного и некорректного предложений и предложение, корректность которого надо оценить."
      ],
      "metadata": {
        "id": "MQXEsdJcNJ5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def liguistic_acceptability(prompts, text):\n",
        "  incorrect_prompt = prompts[0].format(sentence=text)\n",
        "  correct_prompt = prompts[1].format(sentence=text)\n",
        "  incorrect_loss = get_loss_num(incorrect_prompt)\n",
        "  correct_loss = get_loss_num(correct_prompt)\n",
        "  return np.argmax([incorrect_loss, correct_loss])"
      ],
      "metadata": {
        "id": "mxrmiE1INJjo"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "6cGK0AZ_M8RW",
        "outputId": "bc5b360c-046f-4bee-de84-89925fd53e3d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    id                                           sentence  acceptable  \\\n",
              "0    0  Вдруг решетка беззвучно поехала в сторону, и н...           1   \n",
              "1    1                       Этим летом не никуда ездили.           0   \n",
              "2    2  Только Иван выразил какую бы то ни было готовн...           1   \n",
              "3    3  Теперь ты видишь собственными глазами, как тут...           1   \n",
              "4    4    На поверку вся теория оказалась полной чепухой.           1   \n",
              "5    5                      Он всегда сидит в библиотеке.           1   \n",
              "6    6       Представляю, как смешно это выглядело снизу.           1   \n",
              "7    7  Мне предоставилась возможность все видеть, сам...           0   \n",
              "8    8  Наш новый сотрудник оказался коренастым мужчин...           1   \n",
              "9    9  Регистрация была проведена сразу по прибытию у...           0   \n",
              "10  10                     Не думаю, что мосты уже сняли.           1   \n",
              "11  11  Предстояли очередные выборы, на которых он дал...           1   \n",
              "12  12  После собрания кто-то сострил, что пока не раз...           1   \n",
              "13  13          Наблюдается приток иностранного капитала.           1   \n",
              "14  14                     Последние пять человек пришло.           0   \n",
              "\n",
              "   error_type detailed_source  \n",
              "0           0   Paducheva2004  \n",
              "1      Syntax         Rusgram  \n",
              "2           0   Paducheva2013  \n",
              "3           0   Paducheva2010  \n",
              "4           0   Paducheva2010  \n",
              "5           0    Seliverstova  \n",
              "6           0   Paducheva2004  \n",
              "7      Syntax       Testelets  \n",
              "8           0            USE5  \n",
              "9      Syntax            USE8  \n",
              "10          0   Paducheva2013  \n",
              "11          0        Lutikova  \n",
              "12          0   Paducheva2004  \n",
              "13          0   Paducheva2013  \n",
              "14     Syntax       Testelets  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-b767b4b4-b9e5-4080-844e-7c74660c521c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentence</th>\n",
              "      <th>acceptable</th>\n",
              "      <th>error_type</th>\n",
              "      <th>detailed_source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Вдруг решетка беззвучно поехала в сторону, и н...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Paducheva2004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Этим летом не никуда ездили.</td>\n",
              "      <td>0</td>\n",
              "      <td>Syntax</td>\n",
              "      <td>Rusgram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Только Иван выразил какую бы то ни было готовн...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Paducheva2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Теперь ты видишь собственными глазами, как тут...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Paducheva2010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>На поверку вся теория оказалась полной чепухой.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Paducheva2010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Он всегда сидит в библиотеке.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Seliverstova</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>Представляю, как смешно это выглядело снизу.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Paducheva2004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>Мне предоставилась возможность все видеть, сам...</td>\n",
              "      <td>0</td>\n",
              "      <td>Syntax</td>\n",
              "      <td>Testelets</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>Наш новый сотрудник оказался коренастым мужчин...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>USE5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>Регистрация была проведена сразу по прибытию у...</td>\n",
              "      <td>0</td>\n",
              "      <td>Syntax</td>\n",
              "      <td>USE8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>Не думаю, что мосты уже сняли.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Paducheva2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>Предстояли очередные выборы, на которых он дал...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Lutikova</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>После собрания кто-то сострил, что пока не раз...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Paducheva2004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>Наблюдается приток иностранного капитала.</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Paducheva2013</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>Последние пять человек пришло.</td>\n",
              "      <td>0</td>\n",
              "      <td>Syntax</td>\n",
              "      <td>Testelets</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b767b4b4-b9e5-4080-844e-7c74660c521c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-d41909b9-7521-4209-8398-13a6bcf2fde1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d41909b9-7521-4209-8398-13a6bcf2fde1')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-d41909b9-7521-4209-8398-13a6bcf2fde1 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b767b4b4-b9e5-4080-844e-7c74660c521c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b767b4b4-b9e5-4080-844e-7c74660c521c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_v1 = [\n",
        "    'Предложение далее корректное? {sentence} Ответ: нет.',\n",
        "    'Предложение далее корректное? {sentence} Ответ: да.'\n",
        "]"
      ],
      "metadata": {
        "id": "chfZqC8CLJb0"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, s in enumerate(df['sentence'].head(15)):\n",
        "  print(s)\n",
        "  print('Acceptability:', df['acceptable'][i])\n",
        "  prediction = liguistic_acceptability(prompts_v1, s)\n",
        "  print('Predicted acceptability:', prediction)\n",
        "  print()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9l8e2n2aMCdZ",
        "outputId": "400a2434-5d89-4b15-ad3b-938146305e94"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вдруг решетка беззвучно поехала в сторону, и на балконе возникла таинственная фигура, прячущаяся от лунного света, и погрозила Ивану пальцем.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 1\n",
            "\n",
            "Этим летом не никуда ездили.\n",
            "Acceptability: 0\n",
            "Predicted acceptability: 1\n",
            "\n",
            "Только Иван выразил какую бы то ни было готовность помочь.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 1\n",
            "\n",
            "Теперь ты видишь собственными глазами, как тут хорошо.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 0\n",
            "\n",
            "На поверку вся теория оказалась полной чепухой.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 1\n",
            "\n",
            "Он всегда сидит в библиотеке.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 1\n",
            "\n",
            "Представляю, как смешно это выглядело снизу.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 1\n",
            "\n",
            "Мне предоставилась возможность все видеть, сам оставаясь незамеченным.\n",
            "Acceptability: 0\n",
            "Predicted acceptability: 0\n",
            "\n",
            "Наш новый сотрудник оказался коренастым мужчиной лет сорока.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 0\n",
            "\n",
            "Регистрация была проведена сразу по прибытию участников симпозиума в аэропорт.\n",
            "Acceptability: 0\n",
            "Predicted acceptability: 1\n",
            "\n",
            "Не думаю, что мосты уже сняли.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 1\n",
            "\n",
            "Предстояли очередные выборы, на которых он дал согласие баллотироваться в депутаты Совета Союза Верховного Совета СССР на новый срок.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 1\n",
            "\n",
            "После собрания кто-то сострил, что пока не разошлись, надо собрать новое собрание, чтобы подтвердить решение этого собрания.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 1\n",
            "\n",
            "Наблюдается приток иностранного капитала.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 0\n",
            "\n",
            "Последние пять человек пришло.\n",
            "Acceptability: 0\n",
            "Predicted acceptability: 1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_predictions(data, prompts):\n",
        "  sentences = data['sentence']\n",
        "  true_labels = np.array(data['acceptable'])\n",
        "  predicted_labels = []\n",
        "  for s in sentences:\n",
        "    prediction = liguistic_acceptability(prompts, s)\n",
        "    predicted_labels.append(prediction)\n",
        "  predicted_labels = np.array(predicted_labels)\n",
        "  mcc = matthews_corrcoef(true_labels, predicted_labels)\n",
        "  print('Total MCC: %.3f' % mcc)"
      ],
      "metadata": {
        "id": "Wr-NDEItMc23"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_predictions(test, prompts_v1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQsacHffPZsn",
        "outputId": "eb42c6bb-62e4-4aab-e5f1-5058461e7f2f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MCC: 0.080\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получаем коэффициент корреляции, близкий к нулю, т.е. это почти случайное угадывание.\n",
        "\n",
        "Полпробуем другую затравку."
      ],
      "metadata": {
        "id": "kM4_cr7JZN1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_v2 = [\n",
        "    'Предложение далее является грамматически корректным? {sentence} Ответ: нет.',\n",
        "    'Предложение далее является грамматически корректным? {sentence} Ответ: да.'\n",
        "]"
      ],
      "metadata": {
        "id": "aUKGudO6WqpK"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, s in enumerate(df['sentence'].head(15)):\n",
        "  print(s)\n",
        "  print('Acceptability:', df['acceptable'][i])\n",
        "  prediction = liguistic_acceptability(prompts_v2, s)\n",
        "  print('Predicted acceptability:', prediction)\n",
        "  print()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8J2PNcvbHBg",
        "outputId": "e1be0f08-7771-4f5c-ba2a-c7400812918e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вдруг решетка беззвучно поехала в сторону, и на балконе возникла таинственная фигура, прячущаяся от лунного света, и погрозила Ивану пальцем.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 1\n",
            "\n",
            "Этим летом не никуда ездили.\n",
            "Acceptability: 0\n",
            "Predicted acceptability: 1\n",
            "\n",
            "Только Иван выразил какую бы то ни было готовность помочь.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 0\n",
            "\n",
            "Теперь ты видишь собственными глазами, как тут хорошо.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 0\n",
            "\n",
            "На поверку вся теория оказалась полной чепухой.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 1\n",
            "\n",
            "Он всегда сидит в библиотеке.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 1\n",
            "\n",
            "Представляю, как смешно это выглядело снизу.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 1\n",
            "\n",
            "Мне предоставилась возможность все видеть, сам оставаясь незамеченным.\n",
            "Acceptability: 0\n",
            "Predicted acceptability: 1\n",
            "\n",
            "Наш новый сотрудник оказался коренастым мужчиной лет сорока.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 0\n",
            "\n",
            "Регистрация была проведена сразу по прибытию участников симпозиума в аэропорт.\n",
            "Acceptability: 0\n",
            "Predicted acceptability: 1\n",
            "\n",
            "Не думаю, что мосты уже сняли.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 1\n",
            "\n",
            "Предстояли очередные выборы, на которых он дал согласие баллотироваться в депутаты Совета Союза Верховного Совета СССР на новый срок.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 1\n",
            "\n",
            "После собрания кто-то сострил, что пока не разошлись, надо собрать новое собрание, чтобы подтвердить решение этого собрания.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 1\n",
            "\n",
            "Наблюдается приток иностранного капитала.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 0\n",
            "\n",
            "Последние пять человек пришло.\n",
            "Acceptability: 0\n",
            "Predicted acceptability: 1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_predictions(test, prompts_v2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCSiwsPLZswE",
        "outputId": "0b6221c3-54d8-4df8-8822-fec198f76019"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MCC: 0.090\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_v3 = [\n",
        "    'Грамматически корректное предложение: {sentence}',\n",
        "    'Грамматически некорректное предложение: {sentence}'\n",
        "]"
      ],
      "metadata": {
        "id": "hWerJZWIbdNh"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, s in enumerate(df['sentence'].head(15)):\n",
        "  print(s)\n",
        "  print('Acceptability:', df['acceptable'][i])\n",
        "  prediction = liguistic_acceptability(prompts_v3, s)\n",
        "  print('Predicted acceptability:', prediction)\n",
        "  print()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lpmzgisZvQA",
        "outputId": "d7bc80fb-cbd3-412a-f446-1d83ead89f38"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вдруг решетка беззвучно поехала в сторону, и на балконе возникла таинственная фигура, прячущаяся от лунного света, и погрозила Ивану пальцем.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 0\n",
            "\n",
            "Этим летом не никуда ездили.\n",
            "Acceptability: 0\n",
            "Predicted acceptability: 0\n",
            "\n",
            "Только Иван выразил какую бы то ни было готовность помочь.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 0\n",
            "\n",
            "Теперь ты видишь собственными глазами, как тут хорошо.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 1\n",
            "\n",
            "На поверку вся теория оказалась полной чепухой.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 0\n",
            "\n",
            "Он всегда сидит в библиотеке.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 1\n",
            "\n",
            "Представляю, как смешно это выглядело снизу.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 0\n",
            "\n",
            "Мне предоставилась возможность все видеть, сам оставаясь незамеченным.\n",
            "Acceptability: 0\n",
            "Predicted acceptability: 1\n",
            "\n",
            "Наш новый сотрудник оказался коренастым мужчиной лет сорока.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 1\n",
            "\n",
            "Регистрация была проведена сразу по прибытию участников симпозиума в аэропорт.\n",
            "Acceptability: 0\n",
            "Predicted acceptability: 1\n",
            "\n",
            "Не думаю, что мосты уже сняли.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 0\n",
            "\n",
            "Предстояли очередные выборы, на которых он дал согласие баллотироваться в депутаты Совета Союза Верховного Совета СССР на новый срок.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 1\n",
            "\n",
            "После собрания кто-то сострил, что пока не разошлись, надо собрать новое собрание, чтобы подтвердить решение этого собрания.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 0\n",
            "\n",
            "Наблюдается приток иностранного капитала.\n",
            "Acceptability: 1\n",
            "Predicted acceptability: 1\n",
            "\n",
            "Последние пять человек пришло.\n",
            "Acceptability: 0\n",
            "Predicted acceptability: 1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_predictions(test, prompts_v3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EArKIdgSacq7",
        "outputId": "73b53002-e2ec-44a2-9bbd-d7c0a0d93278"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MCC: 0.027\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_v4 = [\n",
        "    'Грамматически верное предложение: {sentence}',\n",
        "    'Грамматически неверное предложение: {sentence}'\n",
        "]"
      ],
      "metadata": {
        "id": "gzzvObWEafvH"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_predictions(test, prompts_v4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdcMF6Vacbst",
        "outputId": "12fc929e-155f-4d35-c78c-c9f247d8c524"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MCC: 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_v5 = [\n",
        "    'Грамматически правильное предложение: {sentence}',\n",
        "    'Грамматически неправильное предложение: {sentence}'\n",
        "]"
      ],
      "metadata": {
        "id": "ujXYpF_wcdPY"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_predictions(test, prompts_v5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMxhPVjCchdr",
        "outputId": "8d5a8fb2-d81d-4bb8-a098-a022c78a0ac1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MCC: -0.021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Two-shot\n",
        "Попробуем затравки с примерами."
      ],
      "metadata": {
        "id": "-NBGX4ileZ9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_2shot = [\n",
        "    'Мне предоставилась возможность все видеть, сам оставаясь незамеченным.',\n",
        "    'Наш новый сотрудник оказался коренастым мужчиной лет сорока.'\n",
        "]"
      ],
      "metadata": {
        "id": "WqgdSV4Oejlm"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def two_shot_prompts(prompts, examples):\n",
        "  incorrect = prompts[0].format(sentence=examples[0])+'\\n' + prompts[1].format(sentence=examples[1])+'\\n'+prompts[0]\n",
        "  correct = prompts[0].format(sentence=examples[0])+'\\n' + prompts[1].format(sentence=examples[1])+'\\n'+prompts[1]\n",
        "  return [incorrect, correct]"
      ],
      "metadata": {
        "id": "ACywbHQAhzDa"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_v1_2shot = two_shot_prompts(prompts_v1, example_2shot)"
      ],
      "metadata": {
        "id": "JR_ozPzihTj5"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_predictions(test, prompts_v1_2shot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q89FkYq9fhKL",
        "outputId": "169d3eab-18b5-4530-d9ea-1f6ba28e4d46"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MCC: 0.059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_v2_2shot = two_shot_prompts(prompts_v2, example_2shot)"
      ],
      "metadata": {
        "id": "UQjPakwnfhHX"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_predictions(test, prompts_v2_2shot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF9hvimOcqi6",
        "outputId": "a6ce8414-b563-426d-e337-6103d9afae3d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MCC: 0.071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_v3_2shot = two_shot_prompts(prompts_v3, example_2shot)"
      ],
      "metadata": {
        "id": "wGmjp3vBgAuv"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_predictions(test, prompts_v3_2shot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkkPIX2zgFBj",
        "outputId": "23115ea9-b8ef-45a4-8552-11a18e6ce3c0"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MCC: 0.017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_v4_2shot = two_shot_prompts(prompts_v4, example_2shot)"
      ],
      "metadata": {
        "id": "LHGW7j_BgGzt"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_predictions(test, prompts_v4_2shot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oq4_u1LMgNLn",
        "outputId": "88171ccc-f175-42f9-b461-6ba8e6b38f62"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MCC: 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_v5_2shot = two_shot_prompts(prompts_v5, example_2shot)"
      ],
      "metadata": {
        "id": "6sPLql-0gOxT"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_predictions(test, prompts_v5_2shot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCIstw0cgTRy",
        "outputId": "53180a0a-0deb-4ed6-dbcd-d6a145d92b66"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MCC: 0.031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Four-shot"
      ],
      "metadata": {
        "id": "VDAu7YUWhFwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_4shot = [\n",
        "    ['Мне предоставилась возможность все видеть, сам оставаясь незамеченным.',\n",
        "    'Наш новый сотрудник оказался коренастым мужчиной лет сорока.'],\n",
        "    ['Последние пять человек пришло.',\n",
        "     'Представляю, как смешно это выглядело снизу.']\n",
        "]"
      ],
      "metadata": {
        "id": "AeeJyosOgV1T"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def four_shot_prompts(prompts, examples):\n",
        "  incorrect = '\\n'.join([prompts[0].format(sentence=examples[0][0]), prompts[1].format(sentence=examples[0][1]),\n",
        "                         prompts[0].format(sentence=examples[1][0]), prompts[1].format(sentence=examples[1][1]),\n",
        "                         prompts[0]])\n",
        "  correct = '\\n'.join([prompts[0].format(sentence=examples[0][0]), prompts[1].format(sentence=examples[0][1]),\n",
        "                         prompts[0].format(sentence=examples[1][0]), prompts[1].format(sentence=examples[1][1]),\n",
        "                         prompts[1]])\n",
        "  return [incorrect, correct]"
      ],
      "metadata": {
        "id": "rD16-EzshFGL"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_v1_4shot = four_shot_prompts(prompts_v1, example_4shot)\n",
        "evaluate_predictions(test, prompts_v1_4shot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTU11f5OlZot",
        "outputId": "cad1536b-4c17-4f98-c344-6732c1bfbda3"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MCC: 0.090\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_v2_4shot = four_shot_prompts(prompts_v2, example_4shot)\n",
        "evaluate_predictions(test, prompts_v2_4shot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWHx6mTbljZQ",
        "outputId": "1ea58b74-f4b8-41c7-8545-43a5b80d3299"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MCC: 0.051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_v3_4shot = four_shot_prompts(prompts_v3, example_4shot)\n",
        "evaluate_predictions(test, prompts_v3_4shot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Jg7jb6Xlk7Q",
        "outputId": "e2d5616b-d012-462c-9670-4d61e0713ada"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MCC: -0.083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_v4_4shot = four_shot_prompts(prompts_v4, example_4shot)\n",
        "evaluate_predictions(test, prompts_v4_4shot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFhIUEVQl9CR",
        "outputId": "67847c5c-7639-4334-c85a-2ced480a8e03"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MCC: 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_v5_4shot = four_shot_prompts(prompts_v5, example_4shot)\n",
        "evaluate_predictions(test, prompts_v5_4shot)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJJQzGg3mS4X",
        "outputId": "ac342ac3-afa7-4b10-f3ed-7083dbc27804"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total MCC: 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Лучший результат: mcc = 0.090, который достигается либо  при использовании four-shot затравки версии 1 (`Предложение далее корректное? {sentence} Ответ: нет.`), либо zero-shot затравки версии 2 (`Предложение далее является грамматически корректным? {sentence} Ответ: нет.`)."
      ],
      "metadata": {
        "id": "QHs3GDj1p-uc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ru-T5\n",
        "На основе https://shivanandroy.com/fine-tune-t5-transformer-with-pytorch/."
      ],
      "metadata": {
        "id": "uuaRS-fcqjbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ll-jKauXrhof",
        "outputId": "35ab4a17-d711-42f6-e8e1-a02bfc116c1e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    T5Tokenizer,\n",
        "    T5ForConditionalGeneration,\n",
        ")"
      ],
      "metadata": {
        "id": "49JY-KCE0gTl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = T5Tokenizer.from_pretrained(\"ai-forever/ruT5-base\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEalk6yfmU1w",
        "outputId": "0c50460d-415b-4e32-83c6-a9e657d900e1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "POS_LABEL = \"yes\"\n",
        "NEG_LABEL = \"no\""
      ],
      "metadata": {
        "id": "ilzTUrEh2GKW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = T5ForConditionalGeneration.from_pretrained(\"ai-forever/ruT5-base\")\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUUX_XuXp18a",
        "outputId": "0f42cdef-49fb-4c15-a55c-ee016394db36"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 768)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in df['sentence']:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,\n",
        "                        max_length = 50,\n",
        "                        truncation = True,\n",
        "                        padding='max_length',\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt',\n",
        "                   )\n",
        "\n",
        "    # Add the encoded sentence to the list.\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "labels = []\n",
        "for label in df['acceptable']:\n",
        "  if label == 1:\n",
        "    target_sequence = POS_LABEL\n",
        "    tokenized_label = tokenizer(target_sequence, truncation=True, max_length=3, padding='max_length', return_tensors = 'pt',)[\"input_ids\"]\n",
        "  elif label == 0:\n",
        "    target_sequence = NEG_LABEL\n",
        "    tokenized_label = tokenizer(target_sequence, truncation=True, max_length=3, padding='max_length', return_tensors = 'pt',)[\"input_ids\"]\n",
        "  else:\n",
        "    raise ValueError(\"Unknown class label\")\n",
        "  labels.append(tokenized_label)\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "labels = torch.cat(labels, dim=0)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', df['sentence'][0])\n",
        "print('Token IDs:', input_ids[0])\n",
        "print('Label:', labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxUBQvVyFnRH",
        "outputId": "fc2450d9-f1b1-4564-e001-e0556f49dce6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  Вдруг решетка беззвучно поехала в сторону, и на балконе возникла таинственная фигура, прячущаяся от лунного света, и погрозила Ивану пальцем.\n",
            "Token IDs: tensor([ 6057, 31163, 25014,  7590,     7,     6,   619,     3,     5,     9,\n",
            "         6730,    13, 10526,   565,   305,  8092,  8504,     3, 25694,  1852,\n",
            "           57,    26,  3933,    99,  2164,     3,     5,    17, 21931,   536,\n",
            "         1759,    18,  5066,     4,     2,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n",
            "Label: tensor([13644,  1096,     2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTwByg71Hj8J",
        "outputId": "8df6470c-33b4-4ab9-c1fa-84e7d22edc61"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7,082 training samples\n",
            "  787 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order.\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "twydgeKYLvbK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Adafactor\n",
        "optimizer = Adafactor(model.parameters(),\n",
        "                  lr = 1e-4, relative_step=False\n",
        "                )"
      ],
      "metadata": {
        "id": "FKZ6VRCQ0cn_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(),\n",
        "                  lr = 1e-5,\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "metadata": {
        "id": "JdbF208Gp-JA"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "# Number of training epochs\n",
        "epochs = 10\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs].\n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "ouoGm93J0GyA"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(preds, labels):\n",
        "  counter = 0\n",
        "  for i in range(len(labels)):\n",
        "    if preds[i] == labels[i]:\n",
        "      counter += 1\n",
        "  return counter / len(labels)"
      ],
      "metadata": {
        "id": "pBGW7dgv0Gu8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss,\n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        ids = batch[0].to(device)\n",
        "        mask = batch[1].to(device)\n",
        "        labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        res = model(\n",
        "            input_ids=ids,\n",
        "            attention_mask=mask,\n",
        "            labels=labels,\n",
        "        )\n",
        "\n",
        "        loss = res['loss']\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value\n",
        "        # from the tensor.\n",
        "        total_train_loss += loss\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        # Unpack this training batch from our dataloader.\n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using\n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Forward pass\n",
        "            generated_ids = model.generate(\n",
        "              input_ids = b_input_ids,\n",
        "              attention_mask = b_input_mask,\n",
        "              max_length=3,\n",
        "              num_beams=2,\n",
        "              repetition_penalty=2.5,\n",
        "              length_penalty=1.0,\n",
        "              early_stopping=True\n",
        "              )\n",
        "        preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
        "        target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True) for t in b_labels]\n",
        "\n",
        "        # Accumulate the validation loss.\n",
        "        #total_eval_loss += loss.item()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += accuracy(preds, target)\n",
        "\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    #avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "\n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "\n",
        "    #print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            #'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jV4i-2UU0Gm4",
        "outputId": "3464d0f6-416a-4d28-d15b-940d0db2ee37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    222.    Elapsed: 0:00:17.\n",
            "  Batch    80  of    222.    Elapsed: 0:00:33.\n",
            "  Batch   120  of    222.    Elapsed: 0:00:49.\n",
            "  Batch   160  of    222.    Elapsed: 0:01:05.\n",
            "  Batch   200  of    222.    Elapsed: 0:01:21.\n",
            "\n",
            "  Average training loss: 12.64\n",
            "  Training epcoh took: 0:01:29\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.00\n",
            "  Validation took: 0:00:14\n",
            "\n",
            "======== Epoch 2 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    222.    Elapsed: 0:00:16.\n",
            "  Batch    80  of    222.    Elapsed: 0:00:32.\n",
            "  Batch   120  of    222.    Elapsed: 0:00:47.\n",
            "  Batch   160  of    222.    Elapsed: 0:01:03.\n",
            "  Batch   200  of    222.    Elapsed: 0:01:19.\n",
            "\n",
            "  Average training loss: 12.69\n",
            "  Training epcoh took: 0:01:27\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.00\n",
            "  Validation took: 0:00:13\n",
            "\n",
            "======== Epoch 3 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    222.    Elapsed: 0:00:16.\n",
            "  Batch    80  of    222.    Elapsed: 0:00:32.\n",
            "  Batch   120  of    222.    Elapsed: 0:00:47.\n",
            "  Batch   160  of    222.    Elapsed: 0:01:03.\n",
            "  Batch   200  of    222.    Elapsed: 0:01:19.\n",
            "\n",
            "  Average training loss: 12.70\n",
            "  Training epcoh took: 0:01:27\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.00\n",
            "  Validation took: 0:00:13\n",
            "\n",
            "======== Epoch 4 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    222.    Elapsed: 0:00:16.\n",
            "  Batch    80  of    222.    Elapsed: 0:00:32.\n",
            "  Batch   120  of    222.    Elapsed: 0:00:47.\n",
            "  Batch   160  of    222.    Elapsed: 0:01:03.\n",
            "  Batch   200  of    222.    Elapsed: 0:01:19.\n",
            "\n",
            "  Average training loss: 12.65\n",
            "  Training epcoh took: 0:01:27\n",
            "\n",
            "Running Validation...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sbp0i8lmf88m"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NAOtzA6xb2Os"
      },
      "execution_count": 120,
      "outputs": []
    }
  ]
}